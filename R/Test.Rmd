---
title: "MBON P2P Survey Optimization"
author: "Jon Lefcheck"
date: "7/18/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(iNEXT)
library(tidyverse)
```

## Optimizing sampling across global surveys

## Import the data

First, let's import and clean up the test data from Argentina.

```{r}
# source functons
source("C:/Users/jslef/OneDrive - Smithsonian Institution/Documents/GitHub/asymmetric/R/covstop.R")

source("C:/Users/jslef/OneDrive - Smithsonian Institution/Documents/GitHub/asymmetric/R/estimateD.new.R")

source("C:/Users/jslef/OneDrive - Smithsonian Institution/Documents/GitHub/asymmetric/R/multSE.R")

# read in data
test <- readxl::read_excel("C:/Users/jslef/OneDrive - Smithsonian Institution/Documents/GitHub/asymmetric/data/ARG-PMADRYN.xlsx", sheet = 1, skip = 15)

# remove summary rows
test <- test[!is.na(test$`Survey date (yyyy-mm-dd)`), ]

# replace NAs with 0
test[, 8:19][is.na(test[, 8:19])] <- 0
```

Next, let's break each sampling location into a separate `data.frame` and store as a list. This will allow us to easily run the following operations at each location.

```{r} 
sites.list <- lapply(unique(test$Site), function(i) {
  
  lapply(unique(test$Strata), function(j) {
    
    dat <- test %>% filter(test$Site == i & test$Strata == j)
    
    return(dat)
    
  } )
  
} )

sites.list <- unlist(sites.list, recursive = F)
```

## Rarefaction & Coverage-based Stopping


Basically, if we construct a sample or individual-based rarefaction curve, at some point continued sampling will not yield any new species. This is the point of total "coverage”.

The diversity within each sample falls somewhere along that curve, either at the asymptote (capturing all species) or somewhere lower along the curve (ie, at a lower level of coverage).

Current practice is to rarefy the diversity of each sample to the same level of “coverage” when comparing estimates of biodiversity. 

But we can invert that idea and ask for a given level of coverage, what is the minimum number of samples or individuals would we need to take to capture that amount of biodiversity? 

The function below takes a community matrix and a level of coverage X (default is 90%), and returns how many samples or individuals would you have to observe at minimum to see X% of all species implied by the data.

In a highly oversampled system, this would be much less than the actual number of samples, and you could reduce effort accordingly. Alternately, it might tell you where you’re undersampling too.


Implement coverage-based stopping:

```{r}

lapply(sites.list, covstop)

```







